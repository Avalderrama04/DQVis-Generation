{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4deb389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# /// script\n",
    "# requires-python = \">=3.12\"\n",
    "# dependencies = [\n",
    "#     \"pandas\",\n",
    "#     \"udi-grammar-py\",\n",
    "# ]\n",
    "# ///"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea79a035",
   "metadata": {},
   "outputs": [],
   "source": [
    "from udi_grammar_py import Chart, Op, rolling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198d673c",
   "metadata": {},
   "source": [
    "Brainstorm\n",
    "- voyager uses data types, some metadata, gets a bunch of possible mappings, and ranks based on perceptually \"best\" and groups.\n",
    "\n",
    "\n",
    "I think a high-level template approach can be\n",
    "1. support a simple templating grammar that includes, entities, fields, types, metadata (cardinality, min/max)\n",
    "2. add a visualization for the tempate, somehow take into account logic (e.g. fields)\n",
    "3. contextualize, map to real data that satisfies constraint of types, or generate data that satisfies\n",
    "\n",
    "\n",
    "example final question\n",
    "How many datasets are there for each organ?\n",
    "\n",
    "Template\n",
    "- How many <entity> are there for each each <entity.field:nominal>\n",
    "\n",
    "Result\n",
    "- bar chart\n",
    "\n",
    "Probably could be a grammar for the template slots.\n",
    "- E<N>: Entity, <N> is a number that identifies it.\n",
    "    e.g. <E1> and <E2> would be two different entities\n",
    "\n",
    "Fields specify entity they are from and their type\n",
    "- E<N>.F<N>:(Q|N|O)\n",
    "    e.g. <E1.F1:Q> is a quantitative field from <E1>\n",
    "\n",
    "\n",
    "This let's us specify questions across entities.\n",
    "\n",
    "- How many <E1> are there for each <E2.F1:N>?\n",
    "\n",
    "\n",
    "todo\n",
    "- how to incorporate relationships?\n",
    "- how to incorporate column metametadata (cardinality, etc)\n",
    "\n",
    "Caveats\n",
    "- if there is only one entity or field we can omit the id\n",
    "- if all fields come from the same entity, E can be omitted\n",
    "- multiple data field types can be specified as <F:(O|N)>\n",
    "- words in [] indicate a for-each\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa61d81e",
   "metadata": {},
   "source": [
    "Question brainstorm:\n",
    "- How many <E> are there, grouped by <E.F1:N>?\n",
    "- How many <E1> are there, grouped by <E2.F1:N>?\n",
    "    how many donors are there, grouped by filetype\n",
    "    how many datasets are there, grouped by sex\n",
    "    (this needs the relationship embedded somehow)\n",
    "- What is the [minimum, median, mean, maximum] <F:Q> for each <F:O>?\n",
    "- What is the [count, frequency] of <F:Q> for each <F:O>?\n",
    "- Is there a correlation between <F1:Q> and <F2:Q>?\n",
    "- How many <E> are there, grouped by <F1:N:C1> and <F2:N:C2>?\n",
    "    (this needs to know the cardinality to pick the visualization)\n",
    "\n",
    "\n",
    "Ok, I think the way to do this is with constraints. See https://docs.google.com/spreadsheets/d/1VG10ab4zY9fLN6PZ2WRTJd1a-4FwiTb0h0jZiCpAJYM/edit?gid=0#gid=0\n",
    "\n",
    "So at a first pass we have the script for creating fully declarative, Q,C,V triples. This training data will be in the form,\n",
    "\n",
    "| Query,Constraints,Specification,Type (question|utterance),Creation_Method (tempalte|LLM|User)\n",
    "\n",
    "Then the contextualizer will take each of those, loop over a list of TableSets to create a table, like\n",
    "\n",
    "| template_query,constraints,expanded_query,spec,type,creation_method,datasets,relationships\n",
    "\n",
    "For a final step, we can then call the paraphraser, which will add some columns for paraphrase params, and paraphrased_query\n",
    "\n",
    "finally, we can have some code to create the json spec from this table.\n",
    "\n",
    "Utterance Brainstorm:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6f1d9a-8c3d-42cc-ac62-274bd8bdd0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "chart = (Chart()\n",
    "    .source(\"asdf\", \"www.example.com/asfd.csv\")\n",
    "    .groupby(\"blarg\")\n",
    "    .rollup({\"number of each type of blarg\": Op.count()})\n",
    "    .mark(\"bar\").x(field=\"blarg\", type=\"ordinal\")\n",
    "    .y(field=\"number of each type of blarg\", type=\"quantitative\")\n",
    ")\n",
    "print(chart.to_json(True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb08d842-310c-44ff-b8d2-f83eb8ab5c46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
